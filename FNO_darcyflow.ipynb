{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FNO_darcyflow.ipynb",
      "provenance": [],
      "mount_file_id": "1Cg5ksN8ls5o1kGsVlp5YVGLU8ay98gOk",
      "authorship_tag": "ABX9TyOIhVI40D8BE8Uag+D+qqEm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravindan98/DeepGalerkin-FourierNeural/blob/main/FNO_darcyflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF5moH_l0awO",
        "outputId": "5c3f80a5-17cf-426d-9176-9aa350ed5353"
      },
      "source": [
        "#RUN this cell as torch.rfft is deprecated with torch 1.8.0\n",
        "!pip install torch==1.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/NSDE_Deep/FNO'\n",
            "/content\n",
            "Collecting torch==1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLzkbUlmcyVF",
        "outputId": "fe91f6b0-358e-4da7-9544-a93d075910c1"
      },
      "source": [
        "!unzip /content/drive/MyDrive/NSDE_Deep/FNO/Datasets/NavierStokes_V1e-4_N20_T50_R256_test.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/NSDE_Deep/FNO/Datasets/NavierStokes_V1e-4_N20_T50_R256_test.zip\n",
            "  inflating: ns_data_V1e-4_N20_T50_R256test.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EisFjt8YuZ4F",
        "outputId": "552193ec-f73c-49f1-e7f7-6123c7f756d3"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NSDE_Deep/FNO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNKGqPbDgB6Y",
        "outputId": "6761afba-c7dd-4b7f-fa3f-e92b7c88b58d"
      },
      "source": [
        "!python scripts/eval.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 64, 64, 10]) torch.Size([20, 64, 64, 20])\n",
            "preprocessing finished, time used: 3.1157831529999385\n",
            "28320833\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/eval.py\", line 190, in <module>\n",
            "    out = model(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"scripts/eval.py\", line 122, in forward\n",
            "    x = self.conv1(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"scripts/eval.py\", line 94, in forward\n",
            "    x1 = self.conv0(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"scripts/eval.py\", line 43, in forward\n",
            "    x_ft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
            "AttributeError: module 'torch' has no attribute 'rfft'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYO5djgFd5jg",
        "outputId": "76621b49-6382-4823-e99d-e907f7fb9c21"
      },
      "source": [
        "!gdown --id 1XbkNleFHSxpitvsRywPPD_CsXTPoSfgl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XbkNleFHSxpitvsRywPPD_CsXTPoSfgl\n",
            "To: /content/drive/My Drive/NSDE_Deep/FNO/pretrained_models/ns_fourier_V1e-3_T50_N4800_ep500_m12_w32\n",
            "9.48MB [00:00, 44.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh4x80c3zWcr"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC3RxvRWzUyb"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from utilities3 import *\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "\n",
        "from timeit import default_timer\n",
        "import scipy.io\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "def compl_mul3d(a, b):\n",
        "    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
        "    op = partial(torch.einsum, \"bixyz,ioxyz->boxyz\")\n",
        "    return torch.stack([\n",
        "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
        "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
        "    ], dim=-1)\n",
        "\n",
        "class SpectralConv3d_fast(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
        "        super(SpectralConv3d_fast, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "        self.modes3 = modes3\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
        "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
        "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.in_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, 2, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
        "            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
        "            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
        "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
        "            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
        "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
        "            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.irfft(out_ft, 3, normalized=True, onesided=True, signal_sizes=(x.size(-3), x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class SimpleBlock2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, modes3, width):\n",
        "        super(SimpleBlock2d, self).__init__()\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.modes3 = modes3\n",
        "        self.width = width\n",
        "        self.fc0 = nn.Linear(13, self.width)\n",
        "\n",
        "        self.conv0 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
        "        self.conv1 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
        "        self.conv2 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
        "        self.conv3 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
        "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
        "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
        "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        size_x, size_y, size_z = x.shape[1], x.shape[2], x.shape[3]\n",
        "\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 4, 1, 2, 3)\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
        "        x = self.bn0(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
        "        x = self.bn1(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
        "        x = self.bn2(x1 + x2)\n",
        "        x = F.relu(x)\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
        "        x = self.bn3(x1 + x2)\n",
        "\n",
        "        x = x.permute(0, 2, 3, 4, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class Net2d(nn.Module):\n",
        "    def __init__(self, modes, width):\n",
        "        super(Net2d, self).__init__()\n",
        "        self.conv1 = SimpleBlock2d(modes, modes, 6, width)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "    def count_params(self):\n",
        "        c = 0\n",
        "        for p in self.parameters():\n",
        "            c += reduce(operator.mul, list(p.size()))\n",
        "\n",
        "        return c\n",
        "\n",
        "\n",
        "t1 = default_timer()\n",
        "\n",
        "TEST_PATH = 'data/ns_data_V1e-4_N20_T50_R256test.mat'\n",
        "\n",
        "\n",
        "ntest = 20\n",
        "\n",
        "sub = 4\n",
        "sub_t = 4\n",
        "S = 64\n",
        "T_in = 10\n",
        "T = 20\n",
        "\n",
        "indent = 3\n",
        "\n",
        "# load data\n",
        "reader = MatReader(TEST_PATH)\n",
        "test_a = reader.read_field('u')[:,::sub,::sub, indent:T_in*4:4] #([0, T_in])\n",
        "test_u = reader.read_field('u')[:,::sub,::sub, indent+T_in*4:indent+(T+T_in)*4:sub_t] #([T_in, T_in + T])\n",
        "\n",
        "print(test_a.shape, test_u.shape)\n",
        "\n",
        "# pad the location information (s,t)\n",
        "S = S * (4//sub)\n",
        "T = T * (4//sub_t)\n",
        "\n",
        "test_a = test_a.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])\n",
        "\n",
        "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
        "gridx = gridx.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T, 1])\n",
        "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
        "gridy = gridy.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T, 1])\n",
        "gridt = torch.tensor(np.linspace(0, 1, T+1)[1:], dtype=torch.float)\n",
        "gridt = gridt.reshape(1, 1, 1, T, 1).repeat([1, S, S, 1, 1])\n",
        "\n",
        "test_a = torch.cat((gridx.repeat([ntest,1,1,1,1]), gridy.repeat([ntest,1,1,1,1]),\n",
        "                       gridt.repeat([ntest,1,1,1,1]), test_a), dim=-1)\n",
        "\n",
        "t2 = default_timer()\n",
        "print('preprocessing finished, time used:', t2-t1)\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# load model\n",
        "model = torch.load('model/ns_fourier_V1e-4_T20_N9800_ep200_m12_w32')\n",
        "\n",
        "print(model.count_params())\n",
        "\n",
        "# test\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
        "myloss = LpLoss(size_average=False)\n",
        "pred = torch.zeros(test_u.shape)\n",
        "index = 0\n",
        "with torch.no_grad():\n",
        "    test_l2 = 0\n",
        "    for x, y in test_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        out = model(x)\n",
        "        pred[index] = out\n",
        "        loss = myloss(out.view(1, -1), y.view(1, -1)).item()\n",
        "        test_l2 += loss\n",
        "        print(index, loss)\n",
        "        index = index + 1\n",
        "print(test_l2/ntest)\n",
        "\n",
        "path = 'eval'\n",
        "scipy.io.savemat('pred/'+path+'.mat', mdict={'pred': pred.cpu().numpy(), 'u': test_u.cpu().numpy()})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY7K67KhgXVy",
        "outputId": "7055eb9f-f475-49f7-c3c9-e991fb20302c"
      },
      "source": [
        "!gdown --id 1pr_Up54tNADCGhF8WLvmyTfKlCD5eEkI\n",
        "!gdown --id 1r3idxpsHa21ijhlu3QQ1hVuXcqnBTO7d\n",
        "!gdown --id 1Z1uxG9R8AdAGJprG5STcphysjm56_0Jf\n",
        "!gdown --id 1ViDqN7nc_VCnMackiXv_d7CHZANAFKzV\n",
        "!gdown --id 1G9IW_2shmfgprPYISYt_YS8xa87p4atu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pr_Up54tNADCGhF8WLvmyTfKlCD5eEkI\n",
            "To: /content/drive/MyDrive/Meet Recordings/NSDE_Deep/FNO/Datasets/NavierStokes_V1e-4_N20_T50_R256_test.zip\n",
            "971MB [01:15, 12.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1r3idxpsHa21ijhlu3QQ1hVuXcqnBTO7d\n",
            "To: /content/drive/My Drive/Meet Recordings/NSDE_Deep/FNO/Datasets/NavierStokes_V1e-3_N5000_T50.zip\n",
            "3.85GB [01:20, 48.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Z1uxG9R8AdAGJprG5STcphysjm56_0Jf\n",
            "To: /content/drive/My Drive/Meet Recordings/NSDE_Deep/FNO/Datasets/Darcy_421.zip\n",
            "3.35GB [02:03, 27.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ViDqN7nc_VCnMackiXv_d7CHZANAFKzV\n",
            "To: /content/drive/My Drive/Meet Recordings/NSDE_Deep/FNO/Datasets/Darcy_241.zip\n",
            "821MB [00:22, 36.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1G9IW_2shmfgprPYISYt_YS8xa87p4atu\n",
            "To: /content/drive/My Drive/Meet Recordings/NSDE_Deep/FNO/Datasets/Burgers_v1000.zip\n",
            "3.17GB [00:51, 61.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFJ7Hvj4waiB",
        "outputId": "520a2f24-78b1-4f36-8083-8e3f4a997d9b"
      },
      "source": [
        "%cd /content/drive/MyDrive/NSDE_Deep/FNO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NSDE_Deep/FNO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2dge_KVxwoi",
        "outputId": "85031367-4f75-4965-b7d2-eecbfe543638"
      },
      "source": [
        "!python /content/drive/MyDrive/NSDE_Deep/FNO/fourier_2d.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1451966464 bytes == 0x55cad3734000 @  0x7fa730fd81e7 0x55cacd405f48 0x55cacd3d09c7 0x7fa6c66f63fa 0x7fa6c6919973 0x7fa6c691e0bd 0x7fa6c69218ee 0x7fa6c69295c0 0x7fa6c691b5f5 0x55cacd3d4050 0x55cacd4c599d 0x55cacd447fe9 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd447e50 0x55cacd3d569a 0x55cacd443c9e 0x55cacd442e0d 0x55cacd3d5e11 0x55cacd416d39 0x55cacd413c84 0x55cacd3d47f2 0x55cacd447d75 0x55cacd442b0e 0x55cacd442813\n",
            "tcmalloc: large alloc 1451966464 bytes == 0x55cb2abec000 @  0x7fa730fd81e7 0x55cacd405f48 0x55cacd3d09c7 0x7fa6c66f63fa 0x7fa6c6919973 0x7fa6c691e0bd 0x7fa6c69218ee 0x7fa6c69295c0 0x7fa6c691b5f5 0x55cacd3d4050 0x55cacd4c599d 0x55cacd447fe9 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd447e50 0x55cacd3d569a 0x55cacd443c9e 0x55cacd442e0d 0x55cacd3d5e11 0x55cacd416d39 0x55cacd413c84 0x55cacd3d47f2 0x55cacd447d75 0x55cacd442b0e 0x55cacd442813\n",
            "tcmalloc: large alloc 1451966464 bytes == 0x55cb814a0000 @  0x7fa730fd81e7 0x55cacd405f48 0x55cacd3d09c7 0x7fa6c66f63fa 0x7fa6c6919973 0x7fa6c691e0bd 0x7fa6c69218ee 0x7fa6c69295c0 0x7fa6c691b5f5 0x55cacd3d4050 0x55cacd4c599d 0x55cacd447fe9 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd443c9e 0x55cacd442b0e 0x55cacd3d577a 0x55cacd447e50 0x55cacd3d569a 0x55cacd443c9e 0x55cacd442e0d 0x55cacd3d5e11 0x55cacd416d39 0x55cacd413c84 0x55cacd3d47f2 0x55cacd447d75 0x55cacd442b0e 0x55cacd442813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ1Tymgw0z1M",
        "outputId": "837e44a7-8b91-4df6-9bd4-e28d778fe6d2"
      },
      "source": [
        "!pip install torch==1.6.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 24kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.0+cu101\n",
            "    Uninstalling torch-1.8.0+cu101:\n",
            "      Successfully uninstalled torch-1.8.0+cu101\n",
            "Successfully installed torch-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJjDYZPg00p2"
      },
      "source": [
        "\"\"\"\n",
        "@author: Zongyi Li\n",
        "This file is the Fourier Neural Operator for 2D problem such as the Darcy Flow discussed in Section 5.2 in the [paper](https://arxiv.org/pdf/2010.08895.pdf).\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "#Complex multiplication\n",
        "def compl_mul2d(a, b):\n",
        "    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "    op = partial(torch.einsum, \"bixy,ioxy->boxy\")\n",
        "    return torch.stack([\n",
        "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
        "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
        "    ], dim=-1)\n",
        "\n",
        "################################################################\n",
        "# fourier layer\n",
        "################################################################\n",
        "class SpectralConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.rfft(x, 2, normalized=True, onesided=True)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.in_channels,  x.size(-2), x.size(-1)//2 + 1, 2, device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.irfft(out_ft, 2, normalized=True, onesided=True, signal_sizes=( x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "class SimpleBlock2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2,  width):\n",
        "        super(SimpleBlock2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        \n",
        "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
        "        input shape: (batchsize, x=s, y=s, c=3)\n",
        "        output: the solution \n",
        "        output shape: (batchsize, x=s, y=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        size_x, size_y = x.shape[1], x.shape[2]\n",
        "\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class Net2d(nn.Module):\n",
        "    def __init__(self, modes, width):\n",
        "        super(Net2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        A wrapper function\n",
        "        \"\"\"\n",
        "\n",
        "        self.conv1 = SimpleBlock2d(modes, modes,  width)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "\n",
        "    def count_params(self):\n",
        "        c = 0\n",
        "        for p in self.parameters():\n",
        "            c += reduce(operator.mul, list(p.size()))\n",
        "\n",
        "        return c\n",
        "\n",
        "################################################################\n",
        "# configs\n",
        "################################################################\n",
        "TRAIN_PATH = 'data/piececonst_r421_N1024_smooth1.mat'\n",
        "TEST_PATH = 'data/piececonst_r421_N1024_smooth2.mat'\n",
        "\n",
        "ntrain = 1000\n",
        "ntest = 100\n",
        "\n",
        "batch_size = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "epochs = 5\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "r = 5\n",
        "h = int(((421 - 1)/r) + 1)\n",
        "s = h\n",
        "\n",
        "################################################################\n",
        "# load data and data normalization\n",
        "################################################################\n",
        "reader = MatReader(TRAIN_PATH)\n",
        "x_train = reader.read_field('coeff')[:ntrain,::r,::r][:,:s,:s]\n",
        "y_train = reader.read_field('sol')[:ntrain,::r,::r][:,:s,:s]\n",
        "\n",
        "reader.load_file(TEST_PATH)\n",
        "x_test = reader.read_field('coeff')[:ntest,::r,::r][:,:s,:s]\n",
        "y_test = reader.read_field('sol')[:ntest,::r,::r][:,:s,:s]\n",
        "\n",
        "x_normalizer = UnitGaussianNormalizer(x_train)\n",
        "x_train = x_normalizer.encode(x_train)\n",
        "x_test = x_normalizer.encode(x_test)\n",
        "\n",
        "y_normalizer = UnitGaussianNormalizer(y_train)\n",
        "y_train = y_normalizer.encode(y_train)\n",
        "\n",
        "grids = []\n",
        "grids.append(np.linspace(0, 1, s))\n",
        "grids.append(np.linspace(0, 1, s))\n",
        "grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
        "grid = grid.reshape(1,s,s,2)\n",
        "grid = torch.tensor(grid, dtype=torch.float)\n",
        "x_train = torch.cat([x_train.reshape(ntrain,s,s,1), grid.repeat(ntrain,1,1,1)], dim=3)\n",
        "x_test = torch.cat([x_test.reshape(ntest,s,s,1), grid.repeat(ntest,1,1,1)], dim=3)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "################################################################\n",
        "# training and evaluation\n",
        "################################################################\n",
        "model = Net2d(modes, width).cuda()\n",
        "print(model.count_params())\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "y_normalizer.cuda()\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_mse = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # loss = F.mse_loss(model(x).view(-1), y.view(-1), reduction='mean')\n",
        "        out = model(x)\n",
        "        out = y_normalizer.decode(out)\n",
        "        y = y_normalizer.decode(y)\n",
        "        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "        train_mse += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    abs_err = 0.0\n",
        "    rel_err = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "            out = model(x)\n",
        "            out = y_normalizer.decode(model(x))\n",
        "\n",
        "            rel_err += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
        "\n",
        "    train_mse/= ntrain\n",
        "    abs_err /= ntest\n",
        "    rel_err /= ntest\n",
        "\n",
        "    t2 = default_timer()\n",
        "    print(ep, t2-t1, train_mse, rel_err)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}